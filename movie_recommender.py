# -*- coding: utf-8 -*-
"""Movie_Recommender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SXlNl4HXUj3O-d8v8tMT0YGOkUg6z8hI

### Recommendation Engine
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import io
from google.colab import files
from scipy.sparse import csr_matrix

def read_data(filename,delimiter,encoding='utf-8'):
  uploaded = files.upload()
  return pd.read_csv(io.BytesIO(uploaded[filename]),delimiter=delimiter,encoding=encoding)

ratings = read_data('u.data','\t')
ratings.columns = ['user_id','movie_id','rating','timestamp']
ratings.head()

items_df = read_data('u.item','|',encoding='latin-1')
items_df.columns = "movie_id|movie_title|release_date|video_release_date|IMDb_URL|unknown|Action|Adventure|Animation|Childrens|Comedy|Crime|Documentary|Drama|Fantasy|Film-Noir|Horror|Musical|Mystery|Romance|Sci-Fi|Thriller|War|Western".split('|')
items_df.head()

"""### Rating Distribution"""

p = ratings.groupby('rating')['rating'].agg(['count'])

movie_count = ratings['movie_id'].nunique()

# get user
user_count = ratings['user_id'].nunique()

# get rating count
rating_count = ratings['user_id'].count()


ax = p.plot(kind = 'barh', legend = False, figsize = (15,10))
plt.title('Total pool: {:,} Movies, {:,} customers, {:,} ratings given'.format(movie_count, user_count, rating_count), fontsize=20)
plt.axis('off')


for i in range(1,6):
    ax.text(p.iloc[i-1][0]/4, i-1, 'Rating {}: {:.0f}%'.format(i, p.iloc[i-1][0]*100 / p.sum()[0]), color = 'white', weight = 'bold')
    
    
plt.show()

"""### Utilitiy Matrix"""

index=list(ratings['user_id'].unique())
columns=list(ratings['movie_id'].unique())
index=sorted(index)
columns=sorted(columns)

 
util_df=pd.pivot_table(data=ratings,values='rating',index='user_id',columns='movie_id')
util_df.head()

"""**Fill all NaN values to 0**"""

util_df = util_df.fillna(0)
util_df.head()

"""Now we implement KNN to find nearest neighbours of movies so features are the user_ratings thus we transpose."""

movie_df = util_df.transpose()
movie_df.head()

"""**Train Test Split**"""

from sklearn.model_selection import train_test_split
train_set,test_set = train_test_split(movie_df.T.reset_index(),test_size=0.2)

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import pairwise_distances
def Knn_movie,test_data,s(dataK=20):
  sorted_neighbours = sorted(data,key=lambda x: cosine_similarity(x[1:].reshape(1,-1),te,test_data,st_data),reverse=True)
  neighbours = [i[0] for i in sorted_neighbours[:K]]
  return neighbours

def get_movie_name(movie_id):
  return items_df.loc[items_df['movie_id'] == movie_id].iloc[0]['movie_title']

recommended_movie_ids = Knn_movies(train_set.values,test_set.values[0][1:].reshape(1,-1))
recommended_movies = [get_movie_name(id) for id in recommended_movie_ids]
print("Movie Recommendations for:",get_movie_name(test_set.values[0][0]))
recommended_movies

"""### Evaluating performance based on intra cosine similarity and coverage"""

total_unique_movies = len(np.unique(train_set.values[:,0]))
print("Unique movies in training set:",total_unique_movies)

cosine_distances = []
movie_recommended = {}
for movie in test_set.values:
  recommendations = Knn_movies(train_set.values,movie[1:].reshape(1,-1))
  for item in recommendations:
    if item in movie_recommended:
      movie_recommended[item] += 1
    else:
      movie_recommended[item] = 1
  
  recommendation_vectors = [movie_df.loc[i - 1].values for i in recommendations]
  cosine_distances.append(np.mean(pairwise_distances(recommendation_vectors,metric='cosine')))

print("Average Intra cosine similarity between recommendations:",np.mean(cosine_distances))
print("Movie Catalog Coverage: ",len(movie_recommended)/total_unique_movies * 100)

"""## Neural Network based rating predictor"""

import keras
from keras import backend as K
from keras.models import Sequential
from keras.layers import Dense , merge
from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop
from keras.utils import to_categorical
from keras.utils.vis_utils import model_to_dot
from keras.callbacks import ReduceLROnPlateau


from keras.layers import Dropout, Flatten,Activation,Input,Embedding
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
import tensorflow as tf
import random as rn
from IPython.display import SVG

from keras.layers.merge import dot
from keras.models import Model

users = ratings['user_id'].unique()
movies = ratings['movie_id'].unique()

userid2idx = {o:i for i,o in enumerate(users)}
movieid2idx = {o:i for i,o in enumerate(movies)}

ratings['user_id'] = ratings['user_id'].apply(lambda x: userid2idx[x])
ratings['movie_id'] = ratings['movie_id'].apply(lambda x: movieid2idx[x])

"""**Splitting train and test**"""

split = np.random.rand(len(ratings)) < 0.8
train = ratings[split]
valid = ratings[~split]
print(train.shape , valid.shape)

n_movies=len(ratings['movie_id'].unique())
n_users=len(ratings['user_id'].unique())
n_latent_factors=64  # hyperparamter to deal with.

"""**Creating Input vectors for user_id and movie_id**"""

user_input=Input(shape=(1,),name='user_input',dtype='int64')
user_embedding=Embedding(n_users,n_latent_factors,name='user_embedding')(user_input)
user_vec =Flatten(name='FlattenUsers')(user_embedding)

movie_input=Input(shape=(1,),name='movie_input',dtype='int64')
movie_embedding=Embedding(n_movies,n_latent_factors,name='movie_embedding')(movie_input)
movie_vec=Flatten(name='FlattenMovies')(movie_embedding)

"""**Dot product**"""

sim=dot([user_vec,movie_vec],name='Simalarity-Dot-Product',axes=1)
model =keras.models.Model([user_input, movie_input],sim)
model.summary()

"""**Setting up loss and optimization algorithm**"""

model.compile(optimizer=Adam(lr=1e-4),loss='mse')

batch_size=128
epochs=50
History = model.fit([train['user_id'],train['movie_id']],train['rating'], batch_size=batch_size,
                              epochs =epochs, validation_data = ([valid['user_id'],valid['movie_id']],valid['rating']),
                              verbose = 1)

"""**graph of Loss W.R.T iterations**"""

from pylab import rcParams
rcParams['figure.figsize'] = 10, 5
import matplotlib.pyplot as plt
plt.plot(History.history['loss'] , 'g')
plt.plot(History.history['val_loss'] , 'b')
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.grid(True)
plt.show()

rating_matrix = movie_df.T.values

threshold = 4 #Threshold rating for recommendation
user_recommendations = {}
movie_recommended = {}
for i in range(10):
  for j in range(rating_matrix.shape[1]):
      if rating_matrix[i][j] == 0:
        predicted_rating = model.predict([[userid2idx[i+1]],[movieid2idx[j+1]]])
        if predicted_rating[0][0] > threshold: #Recommended Movie
            if i+1 in user_recommendations:
              user_recommendations[i+1].append(j+1)
            else:
              user_recommendations[i+1] = [j+1]
            
            if j+1 in movie_recommended:
              movie_recommended[j+1] += 1
            else:
              movie_recommended[j+1] = 1


print("Recommendations for user 1 :")
print([get_movie_name(id) for id in user_recommendations[1]])

"""**Performance Evaluation based on personalization and intra cosine similarity**"""

cosine_distances = []
for user in user_recommendations:
  recommendation_vectors = [movie_df.loc[i - 1].values for i in recommendations]
  cosine_distances.append(np.mean(pairwise_distances(recommendation_vectors,metric='cosine')))

print("Average Intra cosine similarity between recommendations:",np.mean(cosine_distances))
print("Coverage: ",len(movie_recommended)/len(movieid2idx) * 100)

"""## Clustering based recommendation"""

from sklearn.cluster import KMeans

"""Group Users that have rated movies similarly and recommended movies within the group"""

costs = []
threshold = 0.2 ## Threshold difference to find optimal K
k = 2
while True:
    nmodel = KMeans(n_clusters = k).fit(rating_matrix) #Your model
    cost = nmodel.inertia_
    
    if len(costs) > 0 and costs[-1][1] - cost < threshold:
        optimalK = costs[-1][0]
        costs.append([k,cost])
        break
    costs.append([k,cost])

    k += 1
    
costs = np.array(costs)
plt.plot(costs[:,0],costs[:,1])
plt.show()

print("Optimal K",optimalK)

model = KMeans(n_clusters=optimalK).fit(rating_matrix)

"""Creating Groups"""

groups = model.labels_
user_groups = {}
for i in range(len(groups)):
  if groups[i] in user_groups:
    user_groups[groups[i]].append(i+1)
  else:
    user_groups[groups[i]] = [i+1]

for group in sorted(user_groups):
  print("Users in group",group)
  print(user_groups[group])
  print()

rec = []
uid = 4
group  = groups[uid]
neighbours = user_groups[group]
threshold = 4
for j in range(rating_matrix.shape[1]):
  if rating_matrix[uid][j] == 0:
    neighbour_ratings = []
    for k in neighbours:
      if rating_matrix[k][j] != 0 and k != uid:
        neighbour_ratings.append(rating_matrix[k][j])

    if len(neighbour_ratings) > 0 and np.mean(neighbour_ratings) > threshold: #Recommend
       rec.append(j+1)


print("Recommendations for user",uid,"based on cluster:")
print([get_movie_name(id) for id in rec])

